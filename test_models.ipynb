{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from text_rank.evaluation import *\n",
    "# import torch\n",
    "# \n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# summarizer = pipeline(\"summarization\", model=\"KamilAin/bart-base-booksum\", device=device)\n",
    "# data = read_data(\"small_datasets/CNNML_tiny.csv\")\n",
    "# # Perform summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summary = summarizer(str(data[0]), max_length=70, min_length=30, do_sample=False)\n",
    "# # Print the summarized text\n",
    "# print(summary[0]['summary_text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81fa8729a759d508"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_name = \"lidiya/bart-base-samsum\"\n",
    "\n",
    "# Define the prefix and tokenizer\n",
    "prefix = \"summarize: \"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Function to preprocess and tokenize the dataset\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"highlights\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = load_dataset('csv', data_files=\"./tiny_CNN_DM/train_dataset.csv\")\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T03:48:07.302416400Z",
     "start_time": "2023-12-04T03:48:06.881319200Z"
    }
   },
   "id": "6485289196295435"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd52c050398b4745b46cfea7a0dac3a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/189 : < :, Epoch 0.02/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=5\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train[\"train\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./bart_cnn_dailymail_finetuned\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T03:49:11.427862200Z",
     "start_time": "2023-12-04T03:48:12.609887800Z"
    }
   },
   "id": "fb4d61ddf5c7cae6"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michelle Manhart, 38, walked on an American flag to protest racism. She was detained by police. She refused to return the flag. She later was banned from the university of 11,500 students. The rally in Valdosta, Georgia, is expected to draw hundreds to the university.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "from text_rank.evaluation import *\n",
    "def generate_summary(text, model, tokenizer):\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_new_tokens =50, max_length=120, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "model_path = \"./bart_cnn_dailymail_finetuned\"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "data = read_data(\"./tiny_CNN_DM/test_dataset.csv\")\n",
    "example_text = prefix + str(data[0])\n",
    "\n",
    "summary = generate_summary(example_text, model, tokenizer)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T03:52:59.589319Z",
     "start_time": "2023-12-04T03:52:55.675779300Z"
    }
   },
   "id": "8a1126b1f93cfe7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "def data_download():\n",
    "    dataset = load_dataset('kmyoo/cnn-dailymail-v1-tiny')\n",
    "    merged_dataset = concatenate_datasets([dataset['train'], dataset['validation'], dataset['test']])\n",
    "    merged_dataset.to_csv('./tiny_CNN_DM/full_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77262be8ff7103e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_download()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a34d70cab3f06d8"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = './tiny_CNN_DM/full_dataset.csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T03:17:32.603187800Z",
     "start_time": "2023-12-04T03:17:32.565684400Z"
    }
   },
   "id": "98bd770733bd6141"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=1/6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T03:17:33.322785300Z",
     "start_time": "2023-12-04T03:17:33.314784900Z"
    }
   },
   "id": "800943993b61837e"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "train_df.to_csv('./tiny_CNN_DM/train_dataset.csv', index=False)\n",
    "test_df.to_csv('./tiny_CNN_DM/test_dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T03:18:18.077876900Z",
     "start_time": "2023-12-04T03:18:18.038481300Z"
    }
   },
   "id": "5d70b89bdac43110"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d1f50eb01812dca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
