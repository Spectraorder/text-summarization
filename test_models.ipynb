{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:24:45.899526400Z",
     "start_time": "2023-12-09T02:24:45.875948300Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from text_rank.evaluation import *\n",
    "# import torch\n",
    "# \n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# summarizer = pipeline(\"summarization\", model=\"KamilAin/bart-base-booksum\", device=device)\n",
    "# data = read_data(\"small_datasets/CNNML_tiny.csv\")\n",
    "# # Perform summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "# summary = summarizer(str(data[0]), max_length=70, min_length=30, do_sample=False)\n",
    "# # Print the summarized text\n",
    "# print(summary[0]['summary_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:24:45.920613800Z",
     "start_time": "2023-12-09T02:24:45.886473600Z"
    }
   },
   "id": "81fa8729a759d508"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer_type = T5TokenizerFast\n",
    "model_type = T5ForConditionalGeneration\n",
    "\n",
    "# model_name = \"lidiya/bart-base-samsum\"\n",
    "model_name = \"lidiya/bart-large-xsum-samsum\"\n",
    "\n",
    "# Define the prefix and tokenizer\n",
    "prefix = \"summarize: \"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "# Function to preprocess and tokenize the dataset\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"highlights\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = load_dataset('csv', data_files=\"./tiny_CNN_DM/train_dataset.csv\")\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:24:46.686802600Z",
     "start_time": "2023-12-09T02:24:45.902531Z"
    }
   },
   "id": "6485289196295435"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b69dfd2f8ba45368f4165eab92b3c61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/189 : < :, Epoch 0.02/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    warmup_steps=60,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=5\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train[\"train\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./bart_large\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:05.211513100Z",
     "start_time": "2023-12-09T02:24:46.688813900Z"
    }
   },
   "id": "fb4d61ddf5c7cae6"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valdosta State University was forced to cancel classes ahead of rally on Friday ahead of protest. Protesters walked on an American flag to protest racism. Video of the protest shows former Playboy model, Michelle Manhart, struggling with police. She was later arrested and charged with criminal trespass after refusing to return the flag. School administrators said they were 'protecting their right to free speech and civil liberties'\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration\n",
    "from text_rank.evaluation import *\n",
    "def generate_summary(text, model, tokenizer):\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "    inputs.to(device)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_new_tokens =50, max_length=120, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "model_path = \"./bart_large\"\n",
    "tokenizer = BartTokenizerFast.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "data = read_data(\"./tiny_CNN_DM/test_dataset.csv\")\n",
    "example_text = prefix + str(data[0])\n",
    "\n",
    "summary = generate_summary(example_text, model, tokenizer)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:11.645693100Z",
     "start_time": "2023-12-09T02:28:05.212516500Z"
    }
   },
   "id": "8a1126b1f93cfe7b"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "# from datasets import load_dataset, concatenate_datasets\n",
    "# \n",
    "# def data_download():\n",
    "#     dataset = load_dataset('kmyoo/cnn-dailymail-v1-tiny')\n",
    "#     merged_dataset = concatenate_datasets([dataset['train'], dataset['validation'], dataset['test']])\n",
    "#     merged_dataset.to_csv('./tiny_CNN_DM/full_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:11.689354300Z",
     "start_time": "2023-12-09T02:28:11.646701900Z"
    }
   },
   "id": "77262be8ff7103e8"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "# data_download()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:11.696405600Z",
     "start_time": "2023-12-09T02:28:11.662787900Z"
    }
   },
   "id": "4a34d70cab3f06d8"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# \n",
    "# csv_file_path = './tiny_CNN_DM/full_dataset.csv'\n",
    "# df = pd.read_csv(csv_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:11.697404800Z",
     "start_time": "2023-12-09T02:28:11.679298600Z"
    }
   },
   "id": "98bd770733bd6141"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# train_df, test_df = train_test_split(df, test_size=1/6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:11.707475Z",
     "start_time": "2023-12-09T02:28:11.693865900Z"
    }
   },
   "id": "800943993b61837e"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "# train_df.to_csv('./tiny_CNN_DM/train_dataset.csv', index=False)\n",
    "# test_df.to_csv('./tiny_CNN_DM/test_dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:11.727549600Z",
     "start_time": "2023-12-09T02:28:11.708468200Z"
    }
   },
   "id": "5d70b89bdac43110"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:28:11.739596800Z",
     "start_time": "2023-12-09T02:28:11.724015800Z"
    }
   },
   "id": "3d1f50eb01812dca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
